{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Untitled1.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "s4yJVRUBv5Qo"
      },
      "source": [
        "Importing Required Libraries\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6HvwQVHOzirq"
      },
      "source": [
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "from tensorflow.keras.models import Sequential,Model,save_model\n",
        "from tensorflow.keras.layers import Embedding,LSTM,TimeDistributed,RepeatVector,Input,Dense,Flatten"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dPOA7wLRv_mT"
      },
      "source": [
        "Reading Data From  Drive\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "K0sls2zXvP-N",
        "outputId": "d3e79d65-a127-4781-c380-7996054bf7f6"
      },
      "source": [
        "source1 = \"drive/MyDrive/dataset/en.txt\"\n",
        "source2 = \"drive/MyDrive/dataset/dan.txt\"\n",
        "with open(source1, \"r\") as f:\n",
        "  eng = f.read().split(\"\\n\")\n",
        "print(\"this is english\", len(eng)) # Total english sentences \n",
        "with open(source2, \"r\") as f:\n",
        "  dan = f.read().split(\"\\n\")\n",
        "print(\"this is danish\", len(dan)) # Total danish sentences"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "this is english 137860\n",
            "this is danish 137860\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mKQOPv7awQIB"
      },
      "source": [
        "Adding Start and End tags in danish sentences\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-758OhUeu0I1"
      },
      "source": [
        "dan_modified = []\n",
        "for i in dan:\n",
        "  text = \"start \" + i + \" end\"\n",
        "  dan_modified.append(text)"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yzDGy2Afwhcd"
      },
      "source": [
        "Defining Helper Functions"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_6k0AWP_wlZo"
      },
      "source": [
        "# Tokinizing the data i.e converting text data into integers \n",
        "def tokenize(text):\n",
        "  tokenizer = Tokenizer()\n",
        "  tokenizer.fit_on_texts(text)\n",
        "  return tokenizer.texts_to_sequences(text), tokenizer.word_index\n",
        "# Calcilating maximum and minimum length of sentences in the dataset\n",
        "def maximum_and_minimum(data):\n",
        "  max_len = max([len(i) for i in data])\n",
        "  min_len = min([len(i) for i in data])\n",
        "  return max_len, min_len\n",
        "# Making all the sentences of equal length by adding zeros at end\n",
        "def padding(sequences, maxLen):\n",
        "  sequences = pad_sequences(sequences, maxlen=maxLen, padding=\"post\")\n",
        "  return sequences\n",
        "# Pre Processing the data set\n",
        "def preprocess(language):\n",
        "  tokenized_sentences, vocab = tokenize(language)\n",
        "  max_len,min_len = maximum_and_minimum(tokenized_sentences)\n",
        "  sequences = padding(tokenized_sentences, max_len)\n",
        "  return tokenized_sentences, vocab, sequences, max_len"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WRITBoW87ehg",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a815e858-a38b-4585-bd89-31912be2e91f"
      },
      "source": [
        "eng_sentences_tokinzed,eng_vocab,eng_padded_sequences,eng_max_len = preprocess(eng)\n",
        "dan_sentences_tokinzed,dan_vocab,dan_padded_sequences,dan_max_len = preprocess(dan_modified)\n",
        "print(\"Length of english vocabulary\", len(eng_vocab))\n",
        "print(\"Length of danish vocabulary\", len(dan_vocab))\n",
        "# Dividing the dataset into training and testing datasets\n",
        "X_train, X_test, y_train, y_test = train_test_split(eng_padded_sequences, dan_padded_sequences, test_size= 0.2, random_state=42) "
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Length of english vocabulary 199\n",
            "Length of danish vocabulary 286\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QTdtfllpxyxm"
      },
      "source": [
        "Defining Neural Network Model\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yd91YdpatWEm",
        "outputId": "70da5f71-05d0-4975-f18b-73f8814a76fd"
      },
      "source": [
        "input = Input(shape=(eng_max_len,))\n",
        "embed_eng = Embedding(input_dim=len(eng_vocab)+1, output_dim=128)(input)\n",
        "# Encoder\n",
        "lstm1 = LSTM(512, return_state=True)\n",
        "encoder_outputs, state_h, state_c = lstm1(embed_eng)\n",
        "\n",
        "context_vec = [state_h, state_c]\n",
        "\n",
        "# Decoder\n",
        "decoder_inputs = Input(shape=(None,))\n",
        "embed_dan = Embedding(input_dim=len(dan_vocab)+1, output_dim=128)(decoder_inputs)\n",
        "lstm2 = LSTM(512, return_sequences=True, return_state=True)\n",
        "output,_,_ = lstm2(embed_dan, initial_state=context_vec)\n",
        "\n",
        "# Dense layers\n",
        "dense = TimeDistributed(Dense(len(dan_vocab)+1, activation=\"softmax\"))\n",
        "output = dense(output)\n",
        "\n",
        "model = Model([input,decoder_inputs], output)\n",
        "model.compile(optimizer=\"adam\", loss=\"sparse_categorical_crossentropy\", metrics=[\"accuracy\"])\n",
        "print(model.summary())\n",
        "model.fit([X_train, y_train[:,:-1]], y_train.reshape(y_train.shape[0], y_train.shape[1],1)[:,1:], epochs=15, validation_split=0.2)\n",
        "model.save(\"seq2seq.h5\")"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"model_1\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_3 (InputLayer)            [(None, 15)]         0                                            \n",
            "__________________________________________________________________________________________________\n",
            "input_4 (InputLayer)            [(None, None)]       0                                            \n",
            "__________________________________________________________________________________________________\n",
            "embedding_2 (Embedding)         (None, 15, 128)      25600       input_3[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "embedding_3 (Embedding)         (None, None, 128)    36736       input_4[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "lstm_2 (LSTM)                   [(None, 512), (None, 1312768     embedding_2[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "lstm_3 (LSTM)                   [(None, None, 512),  1312768     embedding_3[0][0]                \n",
            "                                                                 lstm_2[0][1]                     \n",
            "                                                                 lstm_2[0][2]                     \n",
            "__________________________________________________________________________________________________\n",
            "time_distributed_1 (TimeDistrib (None, None, 287)    147231      lstm_3[0][0]                     \n",
            "==================================================================================================\n",
            "Total params: 2,835,103\n",
            "Trainable params: 2,835,103\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n",
            "None\n",
            "Epoch 1/15\n",
            "2758/2758 [==============================] - 31s 10ms/step - loss: 1.0877 - accuracy: 0.7037 - val_loss: 0.1995 - val_accuracy: 0.9278\n",
            "Epoch 2/15\n",
            "2758/2758 [==============================] - 28s 10ms/step - loss: 0.1200 - accuracy: 0.9592 - val_loss: 0.0414 - val_accuracy: 0.9859\n",
            "Epoch 3/15\n",
            "2758/2758 [==============================] - 28s 10ms/step - loss: 0.0416 - accuracy: 0.9856 - val_loss: 0.0308 - val_accuracy: 0.9891\n",
            "Epoch 4/15\n",
            "2758/2758 [==============================] - 28s 10ms/step - loss: 0.0295 - accuracy: 0.9893 - val_loss: 0.0245 - val_accuracy: 0.9914\n",
            "Epoch 5/15\n",
            "2758/2758 [==============================] - 28s 10ms/step - loss: 0.0229 - accuracy: 0.9915 - val_loss: 0.0210 - val_accuracy: 0.9923\n",
            "Epoch 6/15\n",
            "2758/2758 [==============================] - 28s 10ms/step - loss: 0.0196 - accuracy: 0.9927 - val_loss: 0.0198 - val_accuracy: 0.9926\n",
            "Epoch 7/15\n",
            "2758/2758 [==============================] - 28s 10ms/step - loss: 0.0167 - accuracy: 0.9937 - val_loss: 0.0191 - val_accuracy: 0.9928\n",
            "Epoch 8/15\n",
            "2758/2758 [==============================] - 28s 10ms/step - loss: 0.0156 - accuracy: 0.9940 - val_loss: 0.0189 - val_accuracy: 0.9929\n",
            "Epoch 9/15\n",
            "2758/2758 [==============================] - 28s 10ms/step - loss: 0.0138 - accuracy: 0.9945 - val_loss: 0.0183 - val_accuracy: 0.9932\n",
            "Epoch 10/15\n",
            "2758/2758 [==============================] - 28s 10ms/step - loss: 0.0125 - accuracy: 0.9951 - val_loss: 0.0180 - val_accuracy: 0.9935\n",
            "Epoch 11/15\n",
            "2758/2758 [==============================] - 28s 10ms/step - loss: 0.0110 - accuracy: 0.9956 - val_loss: 0.0182 - val_accuracy: 0.9935\n",
            "Epoch 12/15\n",
            "2758/2758 [==============================] - 28s 10ms/step - loss: 0.0100 - accuracy: 0.9960 - val_loss: 0.0182 - val_accuracy: 0.9935\n",
            "Epoch 13/15\n",
            "2758/2758 [==============================] - 28s 10ms/step - loss: 0.0089 - accuracy: 0.9964 - val_loss: 0.0189 - val_accuracy: 0.9935\n",
            "Epoch 14/15\n",
            "2758/2758 [==============================] - 28s 10ms/step - loss: 0.0077 - accuracy: 0.9970 - val_loss: 0.0196 - val_accuracy: 0.9935\n",
            "Epoch 15/15\n",
            "2758/2758 [==============================] - 28s 10ms/step - loss: 0.0068 - accuracy: 0.9974 - val_loss: 0.0201 - val_accuracy: 0.9936\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "p2W9G1qhJcx0"
      },
      "source": [
        "Infrence model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q0YS_irPHGR3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b1f45491-8c09-4a52-a738-71892860661e"
      },
      "source": [
        "encoder_model = Model(input, context_vec)\n",
        "encoder_model.save(\"encoder.h5\")\n",
        "print(\"Encoder model Saved!\")\n",
        "\n",
        "decoder_state_h = Input(shape=(512,))\n",
        "decoder_state_c = Input(shape=(512,))\n",
        "decoder_state_inputs = [decoder_state_h, decoder_state_c]\n",
        "\n",
        "decoder_inputs = model.layers[1].output\n",
        "dec_emb_layer = model.layers[3]\n",
        "embed_dan2 = dec_emb_layer(decoder_inputs)\n",
        "\n",
        "lstm2 = model.layers[5]\n",
        "decoder_outputs, state_h, state_c = lstm2(embed_dan2, initial_state= decoder_state_inputs)\n",
        "decoder_states = [state_h, state_c]\n",
        "\n",
        "dense = model.layers[6]\n",
        "decoder_outputs = dense(decoder_outputs)\n",
        "\n",
        "decoder_model = Model(\n",
        "    [decoder_inputs] + decoder_state_inputs, [decoder_outputs] + decoder_states\n",
        ")\n",
        "decoder_model.save(\"decoder.h5\")\n",
        "print(\"Decoder model saved!\")"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Encoder model Saved!\n",
            "Decoder model saved!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YoMada94jMSd"
      },
      "source": [
        "def decode_sequence(seq):\n",
        "  states_value = encoder_model.predict(seq)\n",
        "  # starting the target sequence with start\n",
        "  target_seq = np.zeros((1,1))\n",
        "  target_seq[0,0] = dan_vocab[\"start\"]\n",
        "  stop_condition = False\n",
        "  decoded_sentence = ' '\n",
        "  while not stop_condition:\n",
        "    output_tokens, h, c = decoder_model.predict([target_seq] + states_value)\n",
        "    sampled_token_index = np.argmax(output_tokens[0, -1, :])\n",
        "    if sampled_token_index == 0:\n",
        "      break\n",
        "    else: \n",
        "      a = dan_vocab.keys()\n",
        "      a = list(a)\n",
        "      sampled_token = a[sampled_token_index-1]\n",
        "      if sampled_token!='end':\n",
        "        decoded_sentence += ' '+sampled_token\n",
        "        if sampled_token == 'end' or len(decoded_sentence.split()) >= dan_max_len:\n",
        "          stop_condition = True\n",
        "    target_seq = np.zeros((1,1))\n",
        "    target_seq[0, 0] = sampled_token_index\n",
        "    states_value = [h, c]\n",
        "  return decoded_sentence \n"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jYHs8UcHJywE"
      },
      "source": [
        "To convert tokenized integers back to text\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fVhuD0OCmoH4"
      },
      "source": [
        "def seq2word(seq, vocab):\n",
        "  text = \" \"\n",
        "  for i in seq:\n",
        "    if i!=0 :\n",
        "      dict_keys = vocab.keys()\n",
        "      sample_list = list(dict_keys)\n",
        "      sample = sample_list[i-1]     \n",
        "      text = text + sample + \" \"\n",
        "  return text\n"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uF4nYl8vMCxb"
      },
      "source": [
        "Testing model on test data \n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "F8Zb9_Iaji-q",
        "outputId": "644c1e8c-8fca-4909-bb59-d0c96d703217"
      },
      "source": [
        "for i in range(10):\n",
        "  original_eng = seq2word(X_test[i], eng_vocab)\n",
        "  print(\"Original english sentence:\", original_eng)\n",
        "  original_dan = seq2word(y_test[i], dan_vocab)\n",
        "  original_dan = original_dan.replace(\"start\", \" \")\n",
        "  original_dan = original_dan.replace(\"end\", \" \")\n",
        "  print(\"Original danish sentence :\", original_dan)\n",
        "  predicted_sequence = decode_sequence(X_test[i].reshape(1,15))\n",
        "  print(\"Predicted sentence.      :\", predicted_sequence)\n",
        "  print()"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Original english sentence:  china is usually busy during september but it is sometimes cold in spring \n",
            "Original danish sentence :    kina har normalt travlt i september men det er undertiden koldt om foråret   \n",
            "Predicted sentence.      :   kina har normalt travlt i september men det er undertiden koldt om foråret\n",
            "\n",
            "Original english sentence:  he dislikes pears and peaches \n",
            "Original danish sentence :    han kan ikke lide pærer og ferskner   \n",
            "Predicted sentence.      :   han kan ikke lide pærer og ferskner\n",
            "\n",
            "Original english sentence:  the united states is sometimes rainy during january but it is mild in may \n",
            "Original danish sentence :    usa er nogle gange regnfuldt i januar men det er mildt i maj   \n",
            "Predicted sentence.      :   usa er undertiden regnfuldt i januar men det er mildt i maj\n",
            "\n",
            "Original english sentence:  california is mild during march but it is sometimes rainy in october \n",
            "Original danish sentence :    californien er mild i marts men det er undertiden regnfuldt i oktober   \n",
            "Predicted sentence.      :   californien er mild i marts men det er undertiden regnfuldt i oktober\n",
            "\n",
            "Original english sentence:  he dislikes mangoes and strawberries \n",
            "Original danish sentence :    han kan ikke lide mango og jordbær   \n",
            "Predicted sentence.      :   han kan ikke lide mango og jordbær\n",
            "\n",
            "Original english sentence:  the grapefruit is her favorite fruit but the lemon is your favorite \n",
            "Original danish sentence :    grapefrugten er h es yndlingsfrugt men citronen er din favorit   \n",
            "Predicted sentence.      :   grapefrugten er hendes yndlingsfrugt men citronen er din favorit\n",
            "\n",
            "Original english sentence:  i think translating between english and portuguese is easy \n",
            "Original danish sentence :    jeg synes det er let at oversætte mellem engelsk og portugisisk   \n",
            "Predicted sentence.      :   jeg synes det er let at oversætte mellem engelsk og portugisisk\n",
            "\n",
            "Original english sentence:  your most loved fruit is the apple but his most loved is the peach \n",
            "Original danish sentence :    din mest elskede frugt er æblet men hans mest elskede er fersken   \n",
            "Predicted sentence.      :   din mest elskede frugt er æblet men hans mest elskede er fersknet\n",
            "\n",
            "Original english sentence:  the united states is cold during winter and it is sometimes relaxing in june \n",
            "Original danish sentence :    usa er koldt om vinteren og det slapper undertiden af ​​i juni   \n",
            "Predicted sentence.      :   usa er koldt om vinteren og det slapper af og til i juni\n",
            "\n",
            "Original english sentence:  our most loved fruit is the apple but my most loved is the pear \n",
            "Original danish sentence :    vores mest elskede frugt er æblet men min mest elskede er pæren   \n",
            "Predicted sentence.      :   vores mest elskede frugt er æblet men min mest elskede er pæren\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}